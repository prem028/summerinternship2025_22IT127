# summerinternship2025_22IT127
---

## 📊 Week 1 – Edulyt Analytics Internship
### 📅 02 June 2025 to 06 June 2025

• This was the **onboarding week** at Edulyt India for the Analytics Internship.  
• It focused on understanding project objectives, setting up the tech environment, and receiving technical orientation for the upcoming data analytics tasks.

### ✅ Week 1 Task Outline:

1. Internship Orientation & Tools Setup  
2. Familiarization with Data Analytics Project  
3. Environment Setup – Python, Jupyter, Excel  
4. Overview of Power BI, Pandas, and Sanity Rules  
5. Project briefing & mentorship sessions

### 🛠️ Technologies & Tools:

- Python & Jupyter Notebook  
- Pandas Library  
- Microsoft Excel  
- Power BI (Introductory)  
- Google Meet for daily updates

### 📝 Day-by-Day Progress:

#### Day 1 – Orientation & Onboarding  
• Joined welcome session with Edulyt HR & mentor.  
• Understood internship structure and project theme.  
• Set up workspace with Python, Excel, and Jupyter Lab.

#### Day 2 – Domain Introduction  
• Explored real-world analytics use cases.  
• Studied company datasets and sanity check examples.  
• Gained access to the first internal dataset (XLS format).

#### Day 3 – Technical Setup  
• Installed required libraries: `pandas`, `numpy`, `matplotlib`.  
• Tested initial notebook files and visualized sample data.  
• Confirmed Excel read/write support for `.xls` files.

#### Day 4 – Tool Walkthrough  
• Received guidance on using Excel filters, pivot tables.  
• Walkthrough of Power BI basics: cards, slicers, filters.  
• Explored old intern reports for reference.

#### Day 5 – Preparation for Task 1  
• Discussed Task 1 expectations with mentor.  
• Finalized project folder structure and script template.  
• Ready for execution starting Week 2.

### 📂 Project Files:
- 🗂️ Folder Setup for Analytics Internship  
- 📝 Weekly Report for Week 1  
- 💡 Sample dataset review logs  
- 🔗 Google Meet session notes and mentoring screenshots

### 🔗 Useful References:
- [Pandas Official Docs](https://pandas.pydata.org/docs/)  
- [W3Schools Python Basics](https://www.w3schools.com/python/)  
- [Microsoft Excel Overview](https://support.microsoft.com/en-us/excel)

---

## 📊 Week 2 – Edulyt Analytics Internship
![image](https://github.com/user-attachments/assets/574d2e26-50e5-4884-96f3-456a85393966)


### 📅 09 June 2025 to 13 June 2025

• This week focused on **Data Sanity Checks and Cleaning** using Python and Pandas.  
• The task was provided by Edulyt India as part of their Analytics Internship.  
• We worked on a dataset containing customer transaction details and applied several transformation and validation rules.

### ✅ Week 2 Task Outline:

1. **Perform Sanity Checks** – Remove null values, invalid ages, etc.  
2. **Monthly Data Split** – Convert cumulative data to month-wise format.  
3. **Customer Profiling** – Find top 10 paying customers, monthly spend/repayment.  
4. **Apply Fine Logic** – Fine of 2.9% on late repayments.  
5. **Segment Customers** – Based on spend behavior and profit contribution.  

### 🛠️ Technologies Used:
- Python  
- Pandas  
- NumPy  
- Jupyter Notebook  
- Excel (.xls)

### 📝 Day-by-Day Progress:

#### Day 1 – Dataset Understanding & Null Handling
• Loaded raw `.xls` dataset.  
• Removed null and duplicate rows.  
• Filtered invalid entries like Age < 18.  
• Converted 'Date' column to month format.

#### Day 2 – Monthly Segmentation
• Segmented the dataset month-wise.  
• Handled cumulative values and recalculated per month spend.  
• Grouped by customer and month for insights.

#### Day 3 – Spend & Repayment Calculation
• Calculated total spend and repayment for each customer.  
• Identified top 10 customers by amount repaid.  
• Filtered credit violations where repayment exceeded credit limit.

#### Day 4 – Fine Logic & Segmentation
• Applied 2.9% fine on overdue payments.  
• Segmented customers based on profitability and payment behavior.  
• Created new columns for fines, profit, and segment labels.

#### Day 5 – Report Finalization
• Created summary reports in Excel and Pandas.  
• Generated cleaned `.csv` output.  
• Documented learnings and completed Week 2 report.

### 📂 Project Files:
- 📘 `Edulyet_Task1ipynb.ipynb` – Python notebook for Week 2 task  
- 📄 Cleaned Dataset CSV (generated output)  
- 📝 Weekly Report & Supporting Docs in Word format

### 🔗 Useful References:
- [Pandas Data Cleaning Guide](https://pandas.pydata.org/docs/user_guide/missing_data.html)  
- [RealPython – Data Cleaning](https://realpython.com/python-data-cleaning-numpy-pandas/)  
- [GroupBy Aggregation in Pandas](https://pandas.pydata.org/docs/user_guide/groupby.html)


## 📊 Week 3 – Edulyt Analytics Internship

![cleaning](https://img.icons8.com/external-flat-juicy-fish/60/000000/external-data-cleaning-big-data-flat-flat-juicy-fish.png)

### 📅 16 June 2025 to 20 June 2025

• Focused on cleaning and preprocessing the Bengaluru House Price dataset.  
• Derived new features like BHK and handled missing values, preparing the dataset for modeling.

### ✅ Week 3 Task Outline:

1. Load and explore housing dataset  
2. Drop irrelevant columns (`area_type`, `society`, etc.)  
3. Handle missing/null values using Pandas  
4. Create numerical feature from string data (e.g., `size` to `bhk`)  
5. Export cleaned dataset

### 🛠️ Technologies & Tools:

- Python, Pandas, NumPy  
- Jupyter Notebook  
- Matplotlib  

### 📝 Day-by-Day Progress:

#### Day 1 – Dataset Loading & Initial Inspection  
• Loaded data, checked shape, unique values, and distributions.

#### Day 2 – Cleaning & Dropping Columns  
• Removed non-essential columns like `availability`, `balcony`, and `society`.  
• Identified and removed null values.

#### Day 3 – Feature Engineering  
• Converted `size` column into numerical `bhk`.  
• Used lambda functions and `.apply()` for transformation.

#### Day 4 – Summary Preparation  
• Analyzed distribution of BHK, price, and sqft.  
• Reviewed and saved cleaned dataset.

#### Day 5 – Final Submission  
• Completed documentation in notebook.  
• Submitted cleaned CSV for model development.

### 📂 Project Files:
- 📘 `House_Prediction_Data_Cleaning.ipynb`  
- 📄 Cleaned Dataset CSV  

### 🔗 Useful References:
- [Pandas Missing Data](https://pandas.pydata.org/docs/user_guide/missing_data.html)  
- [Matplotlib Basics](https://matplotlib.org/stable/tutorials/introductory/pyplot.html)

---

## 📊 Week 4 – Edulyt Analytics Internship

![model](https://img.icons8.com/color/48/model--v1.png)

### 📅 23 June 2025 to 27 June 2025

• This week focused on modeling using cleaned house price dataset.  
• Performed outlier detection, created price per sqft feature, and implemented multiple regression models.

### ✅ Week 4 Task Outline:

1. Outlier detection and removal (e.g. abnormal BHK-to-area ratio)  
2. Create derived features like `price_per_sqft`  
3. Encode categorical features  
4. Train-test split and apply Linear Regression, Ridge, Lasso  
5. Evaluate models and finalize best one

### 🛠️ Technologies Used:
- Python, Pandas, NumPy  
- Scikit-learn  
- Jupyter Notebook  
- Matplotlib & Seaborn

### 📝 Day-by-Day Progress:

#### Day 1 – Outlier Analysis  
• Removed inconsistent records with unrealistic sqft or BHKs.

#### Day 2 – Feature Creation  
• Added `price_per_sqft` as a derived field.  
• Standardized input columns.

#### Day 3 – Model Training  
• Applied Linear Regression and Ridge/Lasso models.  
• Used R², RMSE for evaluation.

#### Day 4 – Hyperparameter Tuning  
• Compared performance across models.  
• Selected best model and saved predictions.

#### Day 5 – Documentation  
• Compiled results and created final report.  
• Completed notebook for Week 4 submission.

### 📂 Project Files:
- 📘 `House_Prediction_Modeling.ipynb`  
- 📊 Model Summary Report  
- 📄 Final Prediction CSV  

### 🔗 Useful References:
- [Scikit-learn Linear Regression](https://scikit-learn.org/stable/modules/linear_model.html)  
- [Outlier Detection Techniques](https://towardsdatascience.com/outlier-detection-with-python-1c2b875f6f78)
"""



